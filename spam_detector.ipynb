{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam\n",
       "0    2788\n",
       "1    1813\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data into a Pandas DataFrame\n",
    "url = \"https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv\"\n",
    "data = pd.read_csv(url)\n",
    "data.head()\n",
    "\n",
    "# Make a prediction about which model will perform better (to be done in a markdown cell)\n",
    "\n",
    "# Create the labels set (y) from the \"spam\" column\n",
    "y = data[\"spam\"]\n",
    "\n",
    "# Create the features (X) DataFrame from the remaining columns\n",
    "X = data.drop(columns=[\"spam\"])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing datasets using train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Check the balance of the labels variable (y) using the value_counts function\n",
    "y.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction:\n",
    "I predict that the Random Forest model will outperform the Logistic Regression model in terms of accuracy. Random Forests combine multiple decision trees, which allows them to capture complex, non-linear relationships in the data. On the other hand, Logistic Regression assumes a linear relationship between the features and the target, which may limit its performance if the dataset includes non-linear patterns. However, the performance of each model will depend on the characteristics of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create an instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the Standard Scaler with the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Scale the testing features DataFrame using the transform function\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9261404779145547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a logistic regression model with random_state set to 1\n",
    "lr_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit the logistic regression model using the scaled training data\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the predictions on the testing data labels using the testing feature data\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Evaluate the model's performance by calculating the accuracy score of the model\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9594496741491673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier model with random_state set to 1\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Fit the random forest classifier model using the scaled training data\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the predictions on the testing data labels using the testing feature data\n",
    "rf_predictions = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model's performance by calculating the accuracy score of the model\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Based on the accuracy scores, the results matched the prediction. The Random Forest model (0.9594) outperformed the Logistic Regression model (0.9261). This suggests that the Random Forest model is better suited for this dataset. Logistic Regression, being a linear model, works well when there is a linear relationship between features and the target variable. It is simpler and less prone to overfitting with clean data. However, it assumes linearity, which might not capture the complexities of the data. On the other hand, Random Forest, an ensemble learning method, constructs multiple decision trees and can capture non-linear relationships and interactions between features. It is more robust and less likely to overfit due to the averaging of multiple trees. The higher accuracy of Random Forest indicates the presence of non-linear relationships and complex feature interactions in the dataset, which Logistic Regression might miss. Overall, the Random Forest model's ability to handle non-linear relationships and robustness to overfitting contributed to its better performance, aligning with the prediction that it would perform better in this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
